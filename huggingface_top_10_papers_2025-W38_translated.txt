Hugging Face 주간 인기 논문 Top 10 (2025-W38) - 번역본
출처: https://huggingface.co/papers/week/2025-W38

--- 1. Scaling Agents via Continual Pre-training ---
Link: https://huggingface.co/papers/2509.13310

## Abstract (Original)
Large language models (LLMs) have evolved into agentic systems capable of
autonomous tool use and multi-step reasoning for complex problem-solving.
However, post-training approaches building upon general-purpose foundation
models consistently underperform in agentic tasks, particularly in open-source
implementations. We identify the root cause: the absence of robust agentic
foundation models forces models during post-training to simultaneously learn
diverse agentic behaviors while aligning them to expert demonstrations, thereby
creating fundamental optimization tensions. To this end, we are the first to
propose incorporating Agentic Continual Pre-training (Agentic CPT) into the
deep research agents training pipeline to build powerful agentic foundational
models. Based on this approach, we develop a deep research agent model named
AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve
state-of-the-art performance while retains strong tool-use ability, notably
39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

--- 2. OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling ---
Link: https://huggingface.co/papers/2509.12201

## Abstract (Original)
The field of 4D world modeling - aiming to jointly capture spatial geometry
and temporal dynamics - has witnessed remarkable progress in recent years,
driven by advances in large-scale generative models and multimodal learning.
However, the development of truly general 4D world models remains fundamentally
constrained by the availability of high-quality data. Existing datasets and
benchmarks often lack the dynamic complexity, multi-domain diversity, and
spatial-temporal annotations required to support key tasks such as 4D geometric
reconstruction, future prediction, and camera-control video generation. To
address this gap, we introduce OmniWorld, a large-scale, multi-domain,
multi-modal dataset specifically designed for 4D world modeling. OmniWorld
consists of a newly collected OmniWorld-Game dataset and several curated public
datasets spanning diverse domains. Compared with existing synthetic datasets,
OmniWorld-Game provides richer modality coverage, larger scale, and more
realistic dynamic interactions. Based on this dataset, we establish a
challenging benchmark that exposes the limitations of current state-of-the-art
(SOTA) approaches in modeling complex 4D environments. Moreover, fine-tuning
existing SOTA methods on OmniWorld leads to significant performance gains
across 4D reconstruction and video generation tasks, strongly validating
OmniWorld as a powerful resource for training and evaluation. We envision
OmniWorld as a catalyst for accelerating the development of general-purpose 4D
world models, ultimately advancing machines' holistic understanding of the
physical world.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

--- 3. ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform
  Data ---
Link: https://huggingface.co/papers/2509.15221

## Abstract (Original)
Vision-Language Models (VLMs) have enabled computer use agents (CUAs) that
operate GUIs autonomously, showing great potential, yet progress is limited by
the lack of large-scale, open-source computer use data and foundation models.
In this work, we introduce ScaleCUA, a step toward scaling open-source CUAs. It
offers a large-scale dataset spanning 6 operating systems and 3 task domains,
built via a closed-loop pipeline uniting automated agents with human experts.
Trained on this scaled-up data, ScaleCUA can operate seamlessly across
platforms. Specifically, it delivers strong gains over baselines (+26.6 on
WebArena-Lite-v2, +10.7 on ScreenSpot-Pro) and sets new state-of-the-art
results (94.4% on MMBench-GUI L1-Hard, 60.6% on OSWorld-G, 47.4% on
WebArena-Lite-v2). These findings underscore the power of data-driven scaling
for general-purpose computer use agents. We will release data, models, and code
to advance future research: https://github.com/OpenGVLab/ScaleCUA.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

--- 4. FlowRL: Matching Reward Distributions for LLM Reasoning ---
Link: https://huggingface.co/papers/2509.15207

## Abstract (Original)
We propose FlowRL: matching the full reward distribution via flow balancing
instead of maximizing rewards in large language model (LLM) reinforcement
learning (RL). Recent advanced reasoning models adopt reward-maximizing methods
(\eg, PPO and GRPO), which tend to over-optimize dominant reward signals while
neglecting less frequent but valid reasoning paths, thus reducing diversity. In
contrast, we transform scalar rewards into a normalized target distribution
using a learnable partition function, and then minimize the reverse KL
divergence between the policy and the target distribution. We implement this
idea as a flow-balanced optimization method that promotes diverse exploration
and generalizable reasoning trajectories. We conduct experiments on math and
code reasoning tasks: FlowRL achieves a significant average improvement of
10.0% over GRPO and 5.1% over PPO on math benchmarks, and performs
consistently better on code reasoning tasks. These results highlight reward
distribution-matching as a key step toward efficient exploration and diverse
reasoning in LLM reinforcement learning.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

--- 5. WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for
  Open-Ended Deep Research ---
Link: https://huggingface.co/papers/2509.13312

## Abstract (Original)
This paper tackles open-ended deep research (OEDR), a complex challenge where
AI agents must synthesize vast web-scale information into insightful reports.
Current approaches are plagued by dual-fold limitations: static research
pipelines that decouple planning from evidence acquisition and one-shot
generation paradigms that easily suffer from long-context failure issues like
"loss in the middle" and hallucinations. To address these challenges, we
introduce WebWeaver, a novel dual-agent framework that emulates the human
research process. The planner operates in a dynamic cycle, iteratively
interleaving evidence acquisition with outline optimization to produce a
comprehensive, source-grounded outline linking to a memory bank of evidence.
The writer then executes a hierarchical retrieval and writing process,
composing the report section by section. By performing targeted retrieval of
only the necessary evidence from the memory bank for each part, it effectively
mitigates long-context issues. Our framework establishes a new state-of-the-art
across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and
DeepResearchGym. These results validate our human-centric, iterative
methodology, demonstrating that adaptive planning and focused synthesis are
crucial for producing high-quality, reliable, and well-structured reports.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

--- 6. Hala Technical Report: Building Arabic-Centric Instruction & Translation
  Models at Scale ---
Link: https://huggingface.co/papers/2509.14008

## Abstract (Original)
We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
ARleftrightarrowEN teacher to FP8 (yielding sim2times higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
(leq2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

--- 7. WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic
  Data and Scalable Reinforcement Learning ---
Link: https://huggingface.co/papers/2509.13305

## Abstract (Original)
Transcending human cognitive limitations represents a critical frontier in
LLM training. Proprietary agentic systems like DeepResearch have demonstrated
superhuman capabilities on extremely complex information-seeking benchmarks
such as BrowseComp, a feat previously unattainable. We posit that their success
hinges on a sophisticated reasoning pattern absent in open-source models: the
ability to systematically reduce extreme uncertainty when navigating vast
information landscapes. Based on this insight, we introduce WebSailor, a
complete post-training methodology designed to instill this crucial capability.
Our approach involves generating novel, high-uncertainty tasks through
structured sampling and information obfuscation, RFT cold start, and an
efficient agentic RL training algorithm, Duplicating Sampling Policy
Optimization (DUPO). With this integrated pipeline, WebSailor significantly
outperforms all open-source agents in complex information-seeking tasks,
matching proprietary agents' performance and closing the capability gap.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

--- 8. ReSum: Unlocking Long-Horizon Search Intelligence via Context
  Summarization ---
Link: https://huggingface.co/papers/2509.13313

## Abstract (Original)
Large Language Model (LLM)-based web agents demonstrate strong performance on
knowledge-intensive tasks but are hindered by context window limitations in
paradigms like ReAct. Complex queries involving multiple entities, intertwined
relationships, and high uncertainty demand extensive search cycles that rapidly
exhaust context budgets before reaching complete solutions. To overcome this
challenge, we introduce ReSum, a novel paradigm that enables indefinite
exploration through periodic context summarization. ReSum converts growing
interaction histories into compact reasoning states, maintaining awareness of
prior discoveries while bypassing context constraints. For paradigm adaptation,
we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and
advantage broadcasting to familiarize agents with summary-conditioned
reasoning. Extensive experiments on web agents of varying scales across three
benchmarks demonstrate that ReSum delivers an average absolute improvement of
4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO
training. Notably, with only 1K training samples, our WebResummer-30B (a
ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on
BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web
agents.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

--- 9. Towards General Agentic Intelligence via Environment Scaling ---
Link: https://huggingface.co/papers/2509.13311

## Abstract (Original)
Advanced agentic intelligence is a prerequisite for deploying Large Language
Models in practical, real-world applications. Diverse real-world APIs demand
precise, robust function-calling intelligence, which needs agents to develop
these capabilities through interaction in varied environments. The breadth of
function-calling competence is closely tied to the diversity of environments in
which agents are trained. In this work, we scale up environments as a step
towards advancing general agentic intelligence. This gives rise to two central
challenges: (i) how to scale environments in a principled manner, and (ii) how
to effectively train agentic capabilities from experiences derived through
interactions with these environments. To address these, we design a scalable
framework that automatically constructs heterogeneous environments that are
fully simulated, systematically broadening the space of function-calling
scenarios. We further adapt a two-phase agent fine-tuning strategy: first
endowing agents with fundamental agentic capabilities, then specializing them
for domain-specific contexts. Extensive experiments on agentic benchmarks,
tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model,
AgentScaler, significantly enhances the function-calling capability of models.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

--- 10. WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon
  Agents ---
Link: https://huggingface.co/papers/2509.13309

## Abstract (Original)
Recent advances in deep-research systems have demonstrated the potential for
AI agents to autonomously discover and synthesize knowledge from external
sources. In this paper, we introduce WebResearcher, a novel framework for
building such agents through two key components: (1) WebResearcher, an
iterative deep-research paradigm that reformulates deep research as a Markov
Decision Process, where agents periodically consolidate findings into evolving
reports while maintaining focused workspaces, overcoming the context
suffocation and noise contamination that plague existing mono-contextual
approaches; and (2) WebFrontier, a scalable data synthesis engine that
generates high-quality training data through tool-augmented complexity
escalation, enabling systematic creation of research tasks that bridge the gap
between passive knowledge recall and active knowledge construction. Notably, we
find that the training data from our paradigm significantly enhances tool-use
capabilities even for traditional mono-contextual methods. Furthermore, our
paradigm naturally scales through parallel thinking, enabling concurrent
multi-agent exploration for more comprehensive conclusions. Extensive
experiments across 6 challenging benchmarks demonstrate that WebResearcher
achieves state-of-the-art performance, even surpassing frontier proprietary
systems.

## 초록 (Korean)
번역 중 오류 발생: 3번의 시도 후에도 네트워크 연결에 실패했습니다.

